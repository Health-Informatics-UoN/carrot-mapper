name: carrot-mapper-dev

services:
  db:
    image: postgres:14
    restart: always
    ports:
      - 5432:5432
    environment:
      - POSTGRES_PASSWORD=postgres
      - POSTGRES_DB=postgres
      - POSTGRES_USER=postgres
    volumes:
      - db_data:/var/lib/postgresql/data

  frontend:
    image: carrot-frontend
    build:
      context: app/next-client-app
      dockerfile: Dockerfile
      target: dev
    command: npm run dev
    ports:
      - 3000:3000
    environment:
      - BACKEND_URL=http://api:8000
      - BACKEND_ORIGIN=localhost:8000
      - NEXTAUTH_URL=http://localhost:3000/
      - NEXTAUTH_SECRET=verycomplexsecretkey
      - NEXTAUTH_BACKEND_URL=http://api:8000/api/
      - NODE_ENV=development
      - WATCHPACK_POLLING=true
    volumes:
      - ./app/next-client-app:/app
      - /app/node_modules
      - /app/.next
    depends_on:
      - api

  omop-lite:
    image: ghcr.io/andyrae/omop-lite
    volumes:
      - ./vocabs:/vocabs
    depends_on:
      - db
    environment:
      - DB_PASSWORD=postgres
      - DB_NAME=postgres

  api:
    image: carrot-backend
    build:
      context: app
      dockerfile: api/Dockerfile
    ports:
      - 8000:8000
    environment:
      - FRONTEND_URL=http://frontend:3000
      - ALLOWED_HOSTS=['localhost', '127.0.0.1','api', 'workers']
      - DB_ENGINE=django.db.backends.postgresql
      - DB_HOST=db
      - DB_PORT=5432
      - DB_NAME=postgres
      - DB_USER=postgres
      - DB_PASSWORD=postgres
      - DEBUG=True
      - RULES_QUEUE_NAME=rules-queue
      - WORKERS_UPLOAD_NAME=upload-reports-queue
      - SECRET_KEY=secret
      - WORKERS_URL=http://workers:80
      - WORKERS_RULES_NAME=RulesOrchestrator
      - WORKERS_RULES_KEY=rules_key
      - WORKERS_RULES_EXPORT_NAME=rules-exports-queue
      - STORAGE_CONN_STRING=DefaultEndpointsProtocol=http;AccountName=devstoreaccount1;AccountKey=Eby8vdM02xNOcqFlqUwJPLlmEtlCDXJ1OUzFT50uSRZ6IFsuFq2UVErCz4I6tq/K1SZFPTOtr/KBHBeksoGMGw==;BlobEndpoint=http://azurite:10000/devstoreaccount1;QueueEndpoint=http://azurite:10001/devstoreaccount1;TableEndpoint=http://azurite:10002/devstoreaccount1;
      - SIGNING_KEY=secret
      - STORAGE_TYPE=${STORAGE_TYPE:-azure}
      - MINIO_ENDPOINT=minio:9000
      - MINIO_ACCESS_KEY=minioadmin
      - MINIO_SECRET_KEY=minioadmin
      # Choose `airflow` for testing and development of Airflow.
      - WORKER_SERVICE_TYPE=airflow
      # TODO: update to API v2 when updating Airflow to 3.0.0
      - AIRFLOW_BASE_URL=http://airflow-webserver:8081/api/v1/
      - AIRFLOW_AUTO_MAPPING_DAG_ID=auto_mapping
      - AIRFLOW_SCAN_REPORT_PROCESSING_DAG_ID=scan_report_processing
      - AIRFLOW_RULES_EXPORT_DAG_ID=rules_export
      - AIRFLOW_ADMIN_USERNAME=admin
      - AIRFLOW_ADMIN_PASSWORD=admin
      # To match with the capacity of the production environment
      - DATA_UPLOAD_MAX_MEMORY_SIZE=10485760
    volumes:
      - ./app/api:/api
      - ./app/shared:/shared
    depends_on:
      omop-lite:
        condition: service_completed_successfully

  workers:
    image: carrot-workers
    build:
      context: app
      dockerfile: workers/Dockerfile
    ports:
      - 8080:80
      - 7071:80
    environment:
      # Set Docker to look for secrets locally
      - AzureWebJobsSecretStorageType=files
      - IsEncrypted=false
      - AzureWebJobsStorage=DefaultEndpointsProtocol=http;AccountName=devstoreaccount1;AccountKey=Eby8vdM02xNOcqFlqUwJPLlmEtlCDXJ1OUzFT50uSRZ6IFsuFq2UVErCz4I6tq/K1SZFPTOtr/KBHBeksoGMGw==;BlobEndpoint=http://azurite:10000/devstoreaccount1;QueueEndpoint=http://azurite:10001/devstoreaccount1;TableEndpoint=http://azurite:10002/devstoreaccount1;
      - FUNCTIONS_WORKER_RUNTIME=python
      - STORAGE_CONN_STRING=DefaultEndpointsProtocol=http;AccountName=devstoreaccount1;AccountKey=Eby8vdM02xNOcqFlqUwJPLlmEtlCDXJ1OUzFT50uSRZ6IFsuFq2UVErCz4I6tq/K1SZFPTOtr/KBHBeksoGMGw==;BlobEndpoint=http://azurite:10000/devstoreaccount1;QueueEndpoint=http://azurite:10001/devstoreaccount1;TableEndpoint=http://azurite:10002/devstoreaccount1;
      - APP_URL=http://api:8000/
      - WORKERS_UPLOAD_NAME=upload-reports-queue
      - RULES_QUEUE_NAME=rules-queue
      - RULES_FILE_QUEUE_NAME=rules-exports-queue
      # The address that can be used to reach the function app from outside
      - WEBSITE_HOSTNAME=localhost:7071
      # Database setup
      - DB_ENGINE=django.db.backends.postgresql
      - DB_HOST=db
      - DB_PORT=5432
      - DB_NAME=postgres
      - DB_USER=postgres
      - DB_PASSWORD=postgres
      - PYTHONPATH=/home/site/wwwroot:/home/site/wwwroot/shared
      - STORAGE_TYPE=${STORAGE_TYPE:-azure}
      - MINIO_ENDPOINT=minio:9000
      - MINIO_ACCESS_KEY=minioadmin
      - MINIO_SECRET_KEY=minioadmin
    volumes:
      - ./app/workers:/home/site/wwwroot
      - ./app/shared:/home/site/wwwroot/shared
      # Mount the local secret to Docker container
      - ./app/workers/Secrets:/azure-functions-host/Secrets/
    depends_on:
      - api
      - azurite

  azurite:
    image: mcr.microsoft.com/azure-storage/azurite
    restart: always
    ports:
      - 10000:10000
      - 10001:10001
      - 10002:10002
    command: azurite --blobHost azurite --queueHost azurite --tableHost azurite --location /data --debug /data/debug.log --loose --skipApiVersionCheck
    hostname: azurite
    environment:
      - AZURITE_ACCOUNTS=devstoreaccount1:Eby8vdM02xNOcqFlqUwJPLlmEtlCDXJ1OUzFT50uSRZ6IFsuFq2UVErCz4I6tq/K1SZFPTOtr/KBHBeksoGMGw==

  minio:
    profiles: ["minio"]
    image: minio/minio
    container_name: minio
    restart: always
    command: server /data --console-address ":9001"
    ports:
      - "9000:9000"
      - "9001:9001"
    environment:
      MINIO_ROOT_USER: "minioadmin"
      MINIO_ROOT_PASSWORD: "minioadmin"
      MINIO_BROWSER: "on"
      MINIO_DOMAIN: "minio"
    volumes:
      - minio_data:/data
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 10s
      timeout: 5s
      retries: 5

  airflow-webserver:
    build:
      context: app/airflow
      dockerfile: Dockerfile.webserver
    depends_on:
      - db
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      # Update this connection string to point to your remote PostgreSQL
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://postgres:postgres@db:5432/postgres?options=-csearch_path%3Dairflow
      AIRFLOW__DATABASE__SQL_ALCHEMY_SCHEMA: airflow
      AIRFLOW__CORE__LOAD_EXAMPLES: "false"
      AIRFLOW__WEBSERVER__WEB_SERVER_PORT: 8081
      AIRFLOW__WEBSERVER__SECRET_KEY: "test"
      AIRFLOW__API__AUTH_BACKENDS: airflow.api.auth.backend.basic_auth
      AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: "False"
      AIRFLOW__WEBSERVER__EXPOSE_CONFIG: "False"
      AIRFLOW_CONN_POSTGRES_DB_CONN: postgresql+psycopg2://postgres:postgres@db:5432/postgres
      AIRFLOW_CONN_MINIO_CONN: aws://minioadmin:minioadmin@/?endpoint_url=http://minio:9000
      AIRFLOW_CONN_WASB__CONN: wasb://DefaultEndpointsProtocol=http;AccountName=devstoreaccount1;AccountKey=Eby8vdM02xNOcqFlqUwJPLlmEtlCDXJ1OUzFT50uSRZ6IFsuFq2UVErCz4I6tq/K1SZFPTOtr/KBHBeksoGMGw==;BlobEndpoint=http://azurite:10000/devstoreaccount1;QueueEndpoint=http://azurite:10001/devstoreaccount1;TableEndpoint=http://azurite:10002/devstoreaccount1;
      # Admin user configuration
      AIRFLOW_ADMIN_USERNAME: admin
      AIRFLOW_ADMIN_PASSWORD: admin
      # TODO: add optional admin user configuration in the docs
      # TODO: enable CORS on production
    volumes:
      - ./app/airflow/dags:/opt/airflow/dags
      # TODO: decide which method to set Airflow config, if using the below, set it in the Dockerfile
      # - ./app/airflow/config/airflow.cfg:/opt/airflow/airflow.cfg
    ports:
      # normal port is 8080 but to avoid the conflict with workers, use 8081
      - "8081:8081"

  scheduler:
    build:
      context: app/airflow
      dockerfile: Dockerfile.scheduler
    depends_on:
      - airflow-webserver
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      # Update this connection string to point to your remote PostgreSQL
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://postgres:postgres@db:5432/postgres?options=-csearch_path%3Dairflow
      AIRFLOW__DATABASE__SQL_ALCHEMY_SCHEMA: airflow
      AIRFLOW__WEBSERVER__SECRET_KEY: "test"
      AIRFLOW__API__AUTH_BACKENDS: airflow.api.auth.backend.basic_auth
      AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: "False"
      AIRFLOW__WEBSERVER__EXPOSE_CONFIG: "False"
      AIRFLOW_CONN_POSTGRES_DB_CONN: postgresql+psycopg2://postgres:postgres@db:5432/postgres
      AIRFLOW_CONN_MINIO_CONN: aws://minioadmin:minioadmin@/?endpoint_url=http://minio:9000
      AIRFLOW_CONN_WASB__CONN: wasb://DefaultEndpointsProtocol=http;AccountName=devstoreaccount1;AccountKey=Eby8vdM02xNOcqFlqUwJPLlmEtlCDXJ1OUzFT50uSRZ6IFsuFq2UVErCz4I6tq/K1SZFPTOtr/KBHBeksoGMGw==;BlobEndpoint=http://azurite:10000/devstoreaccount1;QueueEndpoint=http://azurite:10001/devstoreaccount1;TableEndpoint=http://azurite:10002/devstoreaccount1;
      # TODO: enable CORS on production
    volumes:
      - ./app/airflow/dags:/opt/airflow/dags
      # TODO: decide which method to set Airflow config, if using the below, set it in the Dockerfile
      # - ./app/airflow/config/airflow.cfg:/opt/airflow/airflow.cfg

volumes:
  db_data:
  minio_data:
